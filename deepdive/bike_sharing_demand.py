# -*- coding: utf-8 -*-
"""bike_sharing_demand.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C55hgBm7xuHNCvkYE9BYLpUsRj5eeTOv

Kaggle Competition: Bike Sharing Demand
================================

This competition is to expect demand for bike based on public bike usage data.

# Load Data & Packages
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold, cross_val_score, GridSearchCV
from sklearn.metrics import make_scorer
from scipy import stats

"""ggplot style"""

plt.rcParams['axes.unicode_minus'] = False
plt.style.use('ggplot')
# matplotlib.rcParams['axes.unicode_minus'] = False

train = pd.read_csv("/content/drive/My Drive/Colab Notebooks/data/bike-sharing-demand/train.csv", parse_dates=["datetime"])
test = pd.read_csv("/content/drive/My Drive/Colab Notebooks/data/bike-sharing-demand/test.csv", parse_dates=["datetime"])
# print(train.shape)
# print(test.shape)
# print(train.info())
# print(train.head())
# print(train.head(20))
# print(train["temp"].describe())
# print(train.isnull().sum())
# msno.matrix(train, figsize=(10, 8))
# plt.show()

"""# Data preprocessing and Visualization

## datetime
"""

list_datetime = ["year", "month", "day", "hour", "minute", "second", "dayofweek"]
for data in (train, test):
  for date_type in list_datetime:
    data[date_type] = getattr(data["datetime"].dt, date_type)

figure, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(nrows=2, ncols=3)
figure.set_size_inches(18, 12)
axes = [ax1, ax2, ax3, ax4, ax5, ax6]
for idx, date_type in enumerate(list_datetime[:-1]):
  sns.barplot(data=train, x=date_type, y="count", ax=axes[idx])
  axes[idx].set(xlabel=date_type, title=date_type+"_count")
plt.show()

"""## Season, Hour, Workingday"""

figure_bp, axes_bp = plt.subplots(2,2, figsize=(12, 10))
sep_cols = ['whole', 'season', 'holiday', 'workingday']
for idx, col in enumerate(sep_cols):
  if col == 'whole':
    sns.boxplot(data=train, y='count', orient='v', ax=axes_bp[idx // 2][idx % 2])
    axes_bp[idx // 2][idx % 2].set(ylabel='Count', title='Total')
  else:
    sns.boxplot(data=train, y='count', x=col, orient='v', ax=axes_bp[idx // 2][idx % 2])
    axes_bp[idx // 2][idx % 2].set(xlabel=col, ylabel='Count', title=col+'_count')
plt.show()

"""## 24HR Timeline"""

train['dayofweek'].value_counts()

figure_pp, axes_pp = plt.subplots(5, 1, figsize=(18, 16))
list_hue = ['workingday', 'dayofweek', 'weather', 'season']
sns.pointplot(data=train, x='hour', y='count', ax=axes_pp[0])
for idx, h in enumerate(list_hue):
  sns.pointplot(data=train, x='hour', y='count', hue=h, ax=axes_pp[idx+1])
plt.show()

"""## Correlation Heatmap"""

corrMatt = train[['temp', 'atemp', 'casual', 'registered', 'humidity', 'windspeed', 'count']].corr()
mask = np.array(corrMatt)
mask[np.tril_indices_from(mask)] = False
figure_corr, ax_corr = plt.subplots(figsize=(20, 10))
sns.heatmap(corrMatt, mask=mask, vmax=.8, square=True, annot=True)
plt.show()

"""## Temperature, Windspeed, Humidity"""

list_reg = ['temp', 'windspeed', 'humidity']
figure_rp, axes_rp = plt.subplots(1, 3, figsize=(12, 5))
for idx, col in enumerate(list_reg):
  sns.regplot(x=col, y='count', data=train, ax=axes_rp[idx])
plt.show()

"""## Monthly Trend of Bike Demand"""

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 4))
sns.barplot(x='year', y='count', data=train, ax=ax1)
sns.barplot(x='month', y='count', data=train, ax=ax2)
fig, ax3 = plt.subplots(1, 1, figsize=(18,4))
train['year_month'] = train['datetime'].apply(lambda x : '{0}-{1}'.format(x.year, x.month))
sns.barplot(x='year_month', y='count', data=train, ax=ax3)
plt.show()

"""##Remove Outliers"""

trainWithoutOutliers = train[np.abs(train['count'] - train['count'].mean()) <= (3 * train['count'].std())]
plt.scatter(train['count'].index, train['count'])
plt.scatter(trainWithoutOutliers['count'].index, trainWithoutOutliers['count'])
plt.show()

"""## Normal Distribution"""

fig_nd, axes_nd = plt.subplots(2, 2, figsize=(12, 10))
sns.distplot(train['count'], ax=axes_nd[0][0])
stats.probplot(train['count'],dist='norm', fit=True, plot=axes_nd[0][1])
sns.distplot(np.log(trainWithoutOutliers['count']), ax=axes_nd[1][0])
stats.probplot(np.log1p(trainWithoutOutliers['count']), dist='norm', fit=True, plot=axes_nd[1][1])
plt.show()

"""## Predict windspeed where value is 0"""

def predict_windspeed(data):
  dataWind0 = data.loc[data['windspeed'] == 0]
  dataWindNot0 = data.loc[data['windspeed'] != 0]
  wCol = ['season', 'weather', 'humidity', 'month', 'temp', 'year', 'atemp']
  dataWindNot0['windspeed'] = dataWindNot0['windspeed'].astype('str')

  rfModel_wind = RandomForestClassifier()
  rfModel_wind.fit(dataWindNot0[wCol], dataWindNot0['windspeed'])
  wind0Values = rfModel_wind.predict(X=dataWind0[wCol])

  predictWind0 = dataWind0
  predictWindNot0 = dataWindNot0
  predictWind0['windspeed'] = wind0Values  # Predict Windspeed for 0 values
  data = predictWindNot0.append(predictWind0)
  data['windspeed'] = data['windspeed'].astype('float')

  data.reset_index(inplace=True)
  data.drop('index', inplace=True, axis=1)
  return data

def windspeed_plot_after(train, after_train):
  fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(18, 10))
  plt.sca(ax1)
  plt.xticks(rotation=30, ha='right')
  ax1.set(ylabel='Count', title='train windspeed')
  sns.countplot(x='windspeed', data=train, ax=ax1)

  plt.sca(ax2)
  plt.xticks(rotation=30, ha='right')
  ax2.set(ylabel='Count', title='prediction windspeed')
  sns.countplot(x='windspeed', data=after_train, ax=ax2)
  
  plt.show()

"""## Data Modeling

### Create Train, Test dataset
Continuous feature: temp, humidity, windspeed, atemp  
Categorical feature: season, holiday, workingday, weather, dayofweek, month, year, hour
"""

def dataset_case(train, test):
  train = train[np.abs(train['count'] - train['count'].mean()) <= (3 * train['count'].std())]
  categorical_feature_names = ['season', 'holiday', 'workingday', 'weather', 'dayofweek', 'month', 'year', 'hour']
  for var in categorical_feature_names:
    train[var] = train[var].astype('category')
    test[var] = test[var].astype('category')
    X_scaler = StandardScaler()
    scaler_names = ['temp', 'atemp', 'humidity', 'windspeed']
  for var in scaler_names:
    train[var] = X_scaler.fit_transform(train[var].values.reshape(-1, 1))
    test[var] = X_scaler.transform(test[var].values.reshape(-1, 1))
  # Feature Selection
  # feature_names = ['season', 'temp', 'atemp', 'humidity', 'windspeed', 'holiday', 'workingday', 'weather', 'dayofweek', 'month', 'year', 'hour']
  feature_names = ['season', 'temp', 'humidity', 'holiday', 'workingday', 'weather', 'dayofweek', 'year', 'hour']
  X_train = train[feature_names]
  y_train = train['count']
  X_test = test[feature_names]
  return X_train, y_train, X_test

"""### Scoring Model: RMSLE
Penalty on UNDERESTIMATION is the main focus of Root Mean Squared Logarithmic Error Scoring. Lower score, better accuracy.
"""

def rmsle(predicted_values, actual_values):
  predicted_values = np.array(predicted_values)
  actual_values = np.array(actual_values)
  
  log_predict = np.log(predicted_values + 1)
  log_actual = np.log(actual_values + 1)

  difference = (log_predict - log_actual) ** 2
  mean_difference = difference.mean()

  score = np.sqrt(mean_difference)
  return score

# Create Scoring Model Instance
rmsle_scorer = make_scorer(rmsle)

"""### Cross-Validation
Prevent overfitting
"""

def train_and_test_cv(model, train_data, train_label, test, disp):
  k_fold = KFold(n_splits=10, shuffle=True, random_state=0)
  score = cross_val_score(model, train_data, train_label, cv=k_fold, scoring=rmsle_scorer)
  score = score.mean()
  print(disp + ' k-fold CV score: {0:.3f}%'.format(score))
  model.fit(train_data, train_label)
  prediction = model.predict(test)
  print(prediction.shape)
  print(prediction[0:10])
  
  # Visualization
  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
  sns.distplot(train_label, ax=ax1, bins=50)
  ax1.set(title=disp + 'train')
  sns.distplot(prediction, ax=ax2, bins=50)
  ax2.set(title=disp + 'test')
  plt.show()
  return prediction, score

"""### Submission"""

def submission(disp, prediction, score):
  submission = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/bike-sharing-demand/sampleSubmission.csv')

  submission['count'] = prediction
  # print(submission.shape)
  # submission.head()
  submission.to_csv('/content/drive/My Drive/Colab Notebooks/data/bike-sharing-demand/' + disp + 
                    '_{0:.5f}_submission.csv'.format(score), index=False)

final_train, final_y_train, final_test = dataset_case(train, test)
print('final_train', final_train.columns)
print('final_test', final_test.columns)
rf = RandomForestRegressor(n_estimators=500)
prediction_tt, score_tt = train_and_test_cv(rf, final_train, final_y_train, final_test, 'rf')

submission('rf_withoutwind', prediction_tt, score_tt)

"""### GridSearchCV"""

def testGridSearchCV(X_train, y_train, X_test, disp):
  param_grid = {
      'max_depth': [35, 40],
      'n_estimators': [600, 700]
  }
  shuffle_cv = KFold(n_splits=10, shuffle=True, random_state=0)
  models = [RandomForestRegressor()]

  for model in models:
    grid_search = GridSearchCV(model, param_grid=param_grid, cv=shuffle_cv, n_jobs=1, verbose=6, scoring=rmsle_scorer)
    grid_search.fit(X_train, y_train)
    prediction = grid_search.predict(X_test)
    score = grid_search.best_score_
    print(disp + "_BestScore: ", grid_search.best_score_)
    print(disp + "_BestParameter: ", grid_search.best_params_)
    print(disp + "_BestModel: ", grid_search.best_estimator_)
  
  return prediction, score

prediction_gs, score_gs = testGridSearchCV(final_train, final_y_train, final_test, 'rf')
submission('rf_grid_withoutwind', prediction_gs, score_gs)

def finalGridSearchCV(X_train, y_train, X_test):
  param_grid_rf = {
      'max_depth': [30, 35, 40],
      'n_estimators': [500, 600, 700]
  }
  param_grid_gbr = {
      'n_estimators': [2000, 3000, 4000],
      'learning_rate': [0.1],
      'alpha': [0.1, 0.2, 0.3]
  }

  shuffle_cv = KFold(n_splits=10, shuffle=True, random_state=0)
  # models = [RandomForestRegressor(), GradientBoostingRegressor()]
  # model_names = ['rf', 'gbr']
  # param_grid = [param_grid_rf, param_grid_gbr]
  models = [GradientBoostingRegressor()]
  model_names = ['gbr']
  param_grid = [param_grid_gbr]
  rmsle_s = []

  for idx, model in enumerate(models):
    grid_search = GridSearchCV(model, param_grid=param_grid[idx], cv=shuffle_cv, n_jobs=1, verbose=5, scoring=rmsle_scorer)
    y_train_log = np.log1p(y_train)
    grid_search.fit(X_train, y_train_log)
    prediction = grid_search.predict(X_test)
    score = grid_search.best_score_
    print(model_names[idx] + "_BestScore: ", score)
    print(model_names[idx] + "_BestParameter: ", grid_search.best_params_)
    print(model_names[idx] + "_BestModel: ", grid_search.best_estimator_)
    rmsle_s.append(score)
    submission(model_names[idx], np.exp(prediction), score)
  
  d = {'Modelling Algorithm': model_names, 'RMSLE': rmsle_s}
  print('d====', d)

finalGridSearchCV(final_train, final_y_train, final_test)